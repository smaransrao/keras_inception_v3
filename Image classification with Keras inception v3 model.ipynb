{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import statements\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import np_utils\n",
    "np.random.seed(1671) # for reproducibility\n",
    "import os\n",
    "import itertools\n",
    "from itertools import repeat\n",
    "\n",
    "#model based imports\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.layers.core import Activation\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths to image folders for training\n",
    "category1_path = \"/custom_path/all_images_folder/category1\"\n",
    "category2_path = \"/custom_path/all_images_folder/category2\"\n",
    "# ......\n",
    "category10_path = \"/custom_path/all_images_folder/category10\"\n",
    "\n",
    "#Create list of category paths for easier use\n",
    "training_paths = [category1_path, category2_path, ... , category10_path]\n",
    "\n",
    "#path to image folders for testing\n",
    "testing_category1_path = \"/custom_path/all_images_folder/test_images/category1\"\n",
    "testing_category2_path = \"/custom_path/all_images_folder/test_images/category2\"\n",
    "# ......\n",
    "testing_category10_path = \"/custom_path/all_images_folder/test_images/category10\"\n",
    "\n",
    "##Create list of testing category paths for easier use\n",
    "testing_paths = [testing_category1_path, testing_category2_path, ... , testing_category10_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set values\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 128\n",
    "verbose = 1\n",
    "classes = 10 # number of outputs = number of categories\n",
    "optimizer = Adam() # use optimizer of choice\n",
    "val_split=0.2 # how much training data is reserved for validation\n",
    "\n",
    "#Image dimensions\n",
    "img_height = 100\n",
    "img_width = 100\n",
    "\n",
    "#Make list of number of classes\n",
    "categories = []\n",
    "for i in range(classes):\n",
    "    categories.append(i)\n",
    "    \n",
    "#Set limits for each image folder for training data\n",
    "category1 = 100 #max 200\n",
    "category2 = 50 #max 100\n",
    "# ...\n",
    "category10 = 200 #max 940\n",
    "\n",
    "#Create a list of limits for easier use\n",
    "train_limits = [category1, category2, ... , category10]\n",
    "\n",
    "#Set limits for each image folder for testing data\n",
    "teat_category1 = 20 #max 50\n",
    "test_category2 = 20 #max 60\n",
    "# ...\n",
    "test_category10 = 20 #max 100\n",
    "\n",
    "#Create a list of limits for easier use\n",
    "test_limits = [test_category1, test_category2, ... , test_category10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that uses os.listdir to load images\n",
    "def load_images(x, paths, limits):\n",
    "    cat1_images = os.listdir(paths[0])[:limits[0]]\n",
    "    cat2_images = os.listdir(paths[1])[:limits[1]]\n",
    "    cat3_images = os.listdir(paths[2])[:limits[2]]\n",
    "    # ...\n",
    "    cat10_images = os.listdir(paths[9])[:limits[9]]\n",
    "    \n",
    "    #load images for category 1\n",
    "    for i in range(limits[0]):\n",
    "        #load image\n",
    "        img = load_img(paths[0] + bio_images[i], target_size = (img_height,img_width), color_mode = \"grayscale\")\n",
    "        #convert to numpy array\n",
    "        training_img_array = img_to_array(img, dtype=\"float32\")\n",
    "        x.append(training_img_array)\n",
    "    \n",
    "    #load images for category 2\n",
    "    for i in range(limits[1]):\n",
    "        #load image\n",
    "        img = load_img(paths[1] + fibre_images[i], target_size = (img_height,img_width), color_mode = \"grayscale\")\n",
    "        #convert to numpy array\n",
    "        training_img_array = img_to_array(img, dtype=\"float32\")\n",
    "        x.append(training_img_array)\n",
    "    \n",
    "    # .....\n",
    "    \n",
    "    #load images for category 10\n",
    "    for i in range(limits[9]):\n",
    "        #load image\n",
    "        img = load_img(paths[9] + tips_images[i], target_size = (img_height,img_width), color_mode = \"grayscale\")\n",
    "        #convert to numpy array\n",
    "        training_img_array = img_to_array(img, dtype=\"float32\")\n",
    "        x.append(training_img_array)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create labels\n",
    "def create_labels(y, cat, limits):\n",
    "    for (i,j) in zip(cat,limits):\n",
    "        y.extend(repeat(i,j))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images used: 18477\n",
      "Number of training labels created: 18477\n",
      "Shape of training data: (18477, 100, 100, 1)Datatype: float32\n",
      "Training labels shape: (18477, 10)Datatype: float32\n"
     ]
    }
   ],
   "source": [
    "#Create training dataset and labels\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "load_images(x_train, training_paths, train_limits)\n",
    "print(\"Number of training images used: \" + str(len(x_train)))\n",
    "\n",
    "create_labels(y_train, categories, train_limits)\n",
    "print(\"Number of training labels created: \" + str(len(y_train)))\n",
    "\n",
    "#convert x_train from list to nparray of float32\n",
    "x_train = np.asarray(x_train)\n",
    "x_train/=255\n",
    "print(\"Shape of training data: \" + str(x_train.shape) + \"Datatype: \" + str(x_train.dtype))\n",
    "\n",
    "#Converting the labels to arrays\n",
    "y_train = np.asarray(y_train, dtype=\"uint8\")\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, classes)\n",
    "\n",
    "print(\"Training labels shape: \" + str(Y_train.shape) + \"Datatype: \" + str(Y_train.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testing images used: 100\n",
      "Number of testing labels created: 100\n",
      "Shape of testing data: (100, 100, 100, 1)Datatype: float32\n",
      "Testing labels shape: (100, 10)Datatype: float32\n"
     ]
    }
   ],
   "source": [
    "#Create testing dataset and labels\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "load_images(x_test, testing_paths, test_limits)\n",
    "print(\"Number of testing images used: \" + str(len(x_test)))\n",
    "\n",
    "create_labels(y_test, categories, test_limits)\n",
    "print(\"Number of testing labels created: \" + str(len(y_test)))\n",
    "\n",
    "#convert x_train from list to nparray of float32\n",
    "x_test = np.asarray(x_test)\n",
    "x_test/=255\n",
    "print(\"Shape of testing data: \" + str(x_test.shape) + \"Datatype: \" + str(x_test.dtype))\n",
    "\n",
    "#Converting the labels to arrays\n",
    "y_test = np.asarray(y_test, dtype=\"uint8\")\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_test = np_utils.to_categorical(y_test, classes)\n",
    "\n",
    "print(\"Testing labels shape: \" + str(Y_test.shape) + \"Datatype: \" + str(Y_test.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100, 100, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 100, 100, 3)       30        \n",
      "_________________________________________________________________\n",
      "inception_v3 (Model)         (None, 1000)              23851784  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 23,861,824\n",
      "Trainable params: 23,827,392\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model architecture to use inception v3 for grayscale images\n",
    "\n",
    "inception = InceptionV3(weights='imagenet', include_top = True)\n",
    "input_tensor = Input(shape=(img_height,img_width,1))\n",
    "x = Conv2D(3,(3,3),padding='same')(input_tensor)    # x has a dimension of (img_height,img_width,3)\n",
    "out1 = inception(x)\n",
    "out = Dense(10, activation = 'softmax')(out1)\n",
    "\n",
    "model = Model(inputs = input_tensor, outputs = out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile model\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  256/18477 [..............................] - ETA: 13:24:00 - loss: 2.3041 - accuracy: 0.02 - ETA: 17:16:38 - loss: 2.3018 - accuracy: 0.1172"
     ]
    }
   ],
   "source": [
    "#Fit model\n",
    "\n",
    "history = model.fit(x_train, Y_train, batch_size = batch_size, epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate testing score\n",
    "\n",
    "score = model.evaluate(x_test, Y_test, verbose = verbose)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate predictions\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "predictions = np.argmax(y_pred, axis = 1)\n",
    "\n",
    "print(predictions[:20])\n",
    "labels_pred = np.argmax(Y_test, axis= 1)\n",
    "print(labels_pred[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
